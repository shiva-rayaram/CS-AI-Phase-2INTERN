{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154e62fc-f59f-4da9-8b43-0c97758b4760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n",
      "Car detected\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "# Minimum width and height of the rectangle\n",
    "min_width = 80\n",
    "min_height = 80\n",
    "\n",
    "# Allowed offset between pixels\n",
    "offset = 6\n",
    "\n",
    "# Y-position of the counting line\n",
    "line_position = 550\n",
    "\n",
    "# Frames per second of the video\n",
    "fps = 60\n",
    "\n",
    "detections = []\n",
    "\n",
    "def get_center(x, y, w, h):\n",
    "    x_center = int(w / 2)\n",
    "    y_center = int(h / 2)\n",
    "    center_x = x + x_center\n",
    "    center_y = y + y_center\n",
    "    return center_x, center_y\n",
    "\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "background_subtractor = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if the frame is empty\n",
    "    if not ret or frame is None:\n",
    "        break\n",
    "\n",
    "    time = float(1 / fps)\n",
    "    sleep(time)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 5)\n",
    "    img_sub = background_subtractor.apply(blur)\n",
    "    dilate = cv2.dilate(img_sub, np.ones((5, 5)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    dilated = cv2.morphologyEx(dilate, cv2.MORPH_CLOSE, kernel)\n",
    "    dilated = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    cv2.line(frame, (25, line_position), (1200, line_position), (255, 127, 0), 3)\n",
    "    for (i, contour) in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        is_valid_contour = (w >= min_width) and (h >= min_height)\n",
    "        if not is_valid_contour:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        center = get_center(x, y, w, h)\n",
    "        detections.append(center)\n",
    "        cv2.circle(frame, center, 4, (0, 0, 255), -1)\n",
    "\n",
    "        for (center_x, center_y) in detections:\n",
    "            if center_y < (line_position + offset) and center_y > (line_position - offset):\n",
    "                cv2.line(frame, (25, line_position), (1200, line_position), (0, 127, 255), 3)\n",
    "                detections.remove((center_x, center_y))\n",
    "                print(\"Car detected\")\n",
    "\n",
    "    cv2.imshow(\"CS AI PHASE-2 intern\", frame)\n",
    "    cv2.imshow(\"Detection\", dilated)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e513009-eab8-4ace-b37b-5e04eac2f00c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
